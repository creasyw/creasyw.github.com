<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Qiong Wu]]></title>
  <link href="http://creasyw.github.io/atom.xml" rel="self"/>
  <link href="http://creasyw.github.io/"/>
  <updated>2014-06-12T06:27:22-07:00</updated>
  <id>http://creasyw.github.io/</id>
  <author>
    <name><![CDATA[Qiong Wu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Reading note of SICP (5)]]></title>
    <link href="http://creasyw.github.io/blog/2014/05/15/reading-note-of-sicp-5/"/>
    <updated>2014-05-15T00:55:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2014/05/15/reading-note-of-sicp-5</id>
    <content type="html"><![CDATA[<ul>
  <li>The ability to visualize the consequences of the actions under consideration is crucial to becoming an expert programmer.</li>
  <li>Procedures that manipulate procedures, including accept them as arguments or return them as values, are called <em>higher-order procedures</em>. (The <em>sigma</em> summation and the derivative operation are all good/simple examples for the latter case.) This is one of the basic characteristics of <em>factional programming languages</em>.</li>
  <li>The significance of higher-order procedures is that they enable us to represent these abstractions explicitly as elements in our programming language, so that they can be handled just like other computational elements……As programmers, we should be alert to opportunities to identify the underlying abstractions in our programs and to build upon them and generalize them to create more powerful abstractions……It poses challenges for efficient implementation, but the resulting gain in expressive power is enormous.</li>
  <li>As with compound procedures, the main issue is to be addressed is that of abstraction as a technique for coping with complexity, while the data abstraction enables us to erect suitable <em>abstraction barriers</em> between different parts of a program.</li>
  <li>In general, the underlying idea of data abstraction is to identify for each type of data object a basic set of operations in terms of which all manipulations of data objects of that type will be expressed, and then to use only those operations in manipulating the data.</li>
  <li>The approach of <em>stratified design</em> is the notion that a complex system should be structured as a sequence of levels that are described using a sequence of languages. Each level is constructed by combining parts that are regarded as primitive at that level, and the parts constructed at each level are used as primitives at the next level. The language used at each level of a stratified design has primitives, means of combinations, and means of abstraction appropriate to that level of detail.</li>
  <li>(Thoughts) I thought local binding with “let/let*/letrec” are similar to what I did in the imperative programming in a sense that I was telling the program what to do. However, this is not the essence. The local binding is the part of paper which contains the “where…” after a complicated formula. It is the way for data abstract.</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kinetic Chain of Reactions]]></title>
    <link href="http://creasyw.github.io/blog/2014/05/14/kinetic-chain-of-reactions/"/>
    <updated>2014-05-14T23:28:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2014/05/14/kinetic-chain-of-reactions</id>
    <content type="html"><![CDATA[<ul>
  <li>Ideally, every time hitting the ball should be a “kinetic chain of reactions”– the momentum moves from feet to knee, to waist, to shoulder, and finally to the forearm and wrist.</li>
  <li>If I only use part of the chain, I might still hit a good ball, occasionally. But it would consume more energy, and the hitting would be much more unstable.</li>
  <li>Technically speaking, serve is the only way that I can completely control this kinetic chain, because I can control all of the paces and do not need to move around.</li>
  <li>During a point, whenever opponent hits the ball, I should pause and split feet, no matter where I am in the court. This could help me make judgment. More importantly, it is the way to “load energy” and start the “kinetic chain”.</li>
  <li>I have too many aspects to improve, but this might be the most important one.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Thought Process in a Tennis Match]]></title>
    <link href="http://creasyw.github.io/blog/2014/04/12/thought-process-in-a-tennis-match/"/>
    <updated>2014-04-12T13:53:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2014/04/12/thought-process-in-a-tennis-match</id>
    <content type="html"><![CDATA[<p>Last Thursday, I had another win in the league(: In my point of view, I was pretty lucky for the previous victories, but I did have an overwhelming victory this time. I was much better than one month ago (yeah! of course=P), and the opponent was a sub-player, who was weaker than others in the league. Although he had a strong surfing, both his forehand and backhand were not so good. The responses were soft and shallow with only a little bit back spin, which gave me a wide angel to hit either inside-in or inside-out.</p>

<p>When I talked with my coach yesterday, he provided some valuable insights about how I should consider the process of a match</p>

<ul>
  <li>Keep the feet floating while preparing ground stroke.</li>
  <li><strong>Volley is the only way to end a point</strong>. No matter how aggressive the ground strokes are, they are not considered to end the point. Instead, they just <em>build</em> the point. If it ends, let it be. If not, that’s the normal case. It means I should always prepare for the next stroke. And the sad part of the story is that after nine months I still don’t really know how to end a point……</li>
  <li>Do not get frustrated playing with players who consistently send lofty backspin. If he voluntarily hands over the control of pace, I should use it wisely: add more topspin on the returns; actively change the angel; don’t rush to end the point but patiently build it.</li>
  <li>Prepare earlier: decide to use forehand or backhand based on the trajectory; once decided, prepare for the ready position; after the bounce, I should begin the movement of hitting; the center of gravity should put into the front halves of the feet, and always keep the momentum forward while hitting the ball.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Survive on Busy Two weeks]]></title>
    <link href="http://creasyw.github.io/blog/2014/04/05/survive-on-busy-two-weeks/"/>
    <updated>2014-04-05T09:47:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2014/04/05/survive-on-busy-two-weeks</id>
    <content type="html"><![CDATA[<p>I am glad that I could survive on three-hours sleep per day for almost two weeks. Of course, there were quite a few downsides: I felt very weak after the first several days, and the feeling lasted till the end; I lost 1 and dropped the other 2 times of tennis matches in this period; my Github longest streak of contribution stopped at 200 days, which is the date right before my comprehensive defense…</p>

<p>The things that I completed in return include:</p>

<ul>
  <li>A 96-pages thesis for the comprehensive defense</li>
  <li>A collection of decent slides built by Beamer/Latex for defense</li>
  <li>Passed it =D</li>
  <li>A part of one NSF proposal</li>
  <li>One research paper submitted to Globecom’14</li>
  <li>Mid-term II of Game Theory</li>
  <li>One reviewing paper from EuraSip</li>
  <li>The least amount of homework and projects in Coursera that keep me within the schedule</li>
</ul>

<p>Furthermore, there are lots of lessons to take away from this process. Concerning the defense about research, I find myself still need to adjust the strategy handling problems. In research, it is not about getting thing done, but about how to propose the right question (relevant with the basic/advanced theorems of the related fields) and to make at least some sense out of it.</p>

<p>For the research, I should not pile up most of the work to the last week of the due date, especially when I could anticipate this busy schedule months before. In Jan. and Feb., I did waste plenty of time to try out different algorithms handling the problem, but none of them had the “sky-high” performances, so I just kept trying. Eventually, when the time run out, I chose the “sub-optimal” solution and wrote the paper in a hurry. This should not be the right way. Sometimes, when the theoretical merits are fascinating, I might need to only derive the theorems and formulas with some naive simulations. When the trial and error process has to perform, I should set a “early termination” threshold and record every “best effort” in different scenarios. It will help me leisurely handle the due date, and maybe produce more work/papers.</p>

<p>I hope I won’t have this kind of busy schedule again, in the sense that I have a better planning and complete each work as soon as I can.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Strategic Playing for the First Several Sets]]></title>
    <link href="http://creasyw.github.io/blog/2014/03/01/strategic-playing-for-the-first-several-sets/"/>
    <updated>2014-03-01T14:29:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2014/03/01/strategic-playing-for-the-first-several-sets</id>
    <content type="html"><![CDATA[<p>It is worth noting that yesterday I had my first win in the 3.0 league=D 7-5, 3-6, and 10-6 in the tie-breaker set. In today’s lesson, Bob told me a bit more about strategic playing. It was all about probing different aspects of the opponent.</p>

<ul>
  <li>Keep hitting in the middle (or either left or right) as long as I can, and see what is the tolerance of the opponent – whether him or me would get frustrated first and try to make some change.</li>
  <li>Consistently push either his backhand or forehand within a point.</li>
  <li>Driving the ball from side to side and observe the pattern of his transition – does he have a high successful rate for the ground stroke while moving? Is his forehand-to-backhand better or worse than the backhand-to-forehand? Does he tend to hit cross court or staight down to the line?</li>
</ul>

<p>The advanced version will also include the timing of pushing towards the net as well as volley, but I haven’t got there yet… I am still struggling to position myself in the transition of volley, let alone the judgement of lobbing or cut-across from my opponent… So, there is a long way to go(:</p>

<p>[Update March 7] The control of my ground stroke is nice, but the hitting point is far from optimal – I should keep the racquet a little bit “closer” and the hitting point should be a little bit in front while the racquet rising in its maximum speed and facing towards the net. Still, The target zone is “higher in the net”.</p>

<p>[Update March 15] The way to increase spin is to make the preparison faster and to prepare the racquet a little bit lower–all movements should be done before the bonuce.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Plotting in Latex]]></title>
    <link href="http://creasyw.github.io/blog/2014/02/27/plotting-in-latex/"/>
    <updated>2014-02-27T13:14:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2014/02/27/plotting-in-latex</id>
    <content type="html"><![CDATA[<p>I just hope that I could find this feature earlier. <a href="http://www.texample.net/tikz/">TikZ</a></p>

<p>Some nice examples to start with:</p>

<ul>
  <li><a href="http://commons.wikimedia.org/wiki/File:Neighbourhood_definition2.svg">Neighbourhood definition</a></li>
  <li><a href="http://www.texample.net/tikz/examples/highlighting-matrix/">Highlighting elements in matrices</a></li>
  <li><a href="http://www.texample.net/tikz/examples/more-tikz-timing-examples/">Signal timing</a></li>
  <li><a href="http://www.texample.net/tikz/examples/bode-plot/">Body plot of functions</a></li>
  <li><a href="http://www.texample.net/tikz/examples/database-decimation-process/">Database decimation process</a></li>
  <li><a href="http://www.texample.net/tikz/examples/labs-schema/">Flowchart with block highlights</a></li>
  <li><a href="http://www.texample.net/tikz/examples/set-operations-illustrated-with-venn-diagrams/">Set operations</a></li>
  <li><a href="http://www.texample.net/tikz/examples/credit-rationing/">Cross-comparsion among curves</a></li>
  <li><a href="http://www.texample.net/tikz/examples/phasor-diagram/">Phasor diagram (more fancy)</a></li>
  <li><a href="http://www.texample.net/tikz/examples/difference-quotient/">Difference quotient (partial zoom-in)</a></li>
  <li><a href="http://www.texample.net/tikz/examples/nested-grids-in-swan-and-wam-coupling/">Nested Grids</a></li>
  <li><a href="http://www.texample.net/tikz/examples/fir-filter/">Digital Signal Processing Library</a></li>
</ul>

<p>More examples can be found in <a href="http://www.texample.net/tikz/examples/">the official site</a>, <a href="http://graphtheoryinlatex.wordpress.com/">Graph Theory in LaTeX 2</a>, <a href="http://elishapeterson.wikidot.com/tikz:diagrams">Drawing Trace Diagrams</a>, and <a href="http://www.statistiker-wg.de/pgf/tutorials.htm">TikZ tutorials</a>.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Better look for "git log"]]></title>
    <link href="http://creasyw.github.io/blog/2014/02/24/better-look-for-git-log/"/>
    <updated>2014-02-24T13:30:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2014/02/24/better-look-for-git-log</id>
    <content type="html"><![CDATA[<p>The first time that I read it is from coolshell.cn, and then today from <a href="http://www.reddit.com/r/programming/comments/1yqiq8/git_log_is_so_2005/">reddit</a>. Just put here as a backup.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">git config --global alias.lg <span class="s2">&quot;log --color --graph --pretty=format:&#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr)%C(bold blue)&lt;%an&gt;%Creset&#39; --abbrev-commit&quot;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The afterwards effect is something like:</p>

<p><img class="center" src="http://creasyw.github.io/images/git_lg.png" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Emacs Progression Path]]></title>
    <link href="http://creasyw.github.io/blog/2014/01/02/emacs-progression-path/"/>
    <updated>2014-01-02T16:37:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2014/01/02/emacs-progression-path</id>
    <content type="html"><![CDATA[<p>I was hoping to find something like <a href="http://stackoverflow.com/questions/2573135/python-progression-path-from-apprentice-to-guru">Python Progression Path</a> or sort of “best practice” for Emacs, because the difference between Vim and Emacs was much larger than I thought. But what I found were either teaching about basic operations such as saving and quiting the editor for people who had access to comupter for the 1st time, or talking about tricks of using Emacs Lisp for the high-end hard-core players… It seemed like I was stuck in the middle, and would stay there for a very long time…</p>

<p>I will sort the contents here as incremental records simulating my Emacs learning process, as well as keeping track of nontrivial materials and thoughts.</p>

<h3 id="resources">Resources:</h3>

<ul>
  <li><a href="http://sachachua.com/blog/2013/05/how-to-learn-emacs-a-hand-drawn-one-pager-for-beginners/">Tow</a> <a href="http://sachachua.com/p/26006">pics</a> served as the very beginning of entering the world of Emacs.</li>
  <li>Cheat Sheet (<a href="http://refcards.com/docs/gildeas/gnu-emacs/emacs-refcard-a4.pdf">compact version</a>, and <a href="http://cs.iupui.edu/~kweimer/EmacsCheatSheet.pdf">a more user friendly verion</a>).</li>
  <li>C-h t. Tutorial of Emacs within the editor. It should be the first doc to read.</li>
  <li>My previous <a href="http://wqiong.com/blog/2013/07/01/setup-emacs-in-mac-os/">post</a> to setup Emacs in Mac OS.</li>
  <li>Steve Yegge’s suggestion for <a href="https://sites.google.com/site/steveyegge2/effective-emacs">improving productivity with Emacs</a></li>
  <li><a href="http://batsov.com/prelude/">Prelude</a> – very easy to setup, and add/disable modules.</li>
  <li><a href="https://github.com/xiaohanyu/oh-my-emacs">Oh-my-emacs</a> is another option to start with, but I met quite a few incompatible issues for the mac os. <a href="https://github.com/eschulte/emacs24-starter-kit">Emacs24 Starter Kit</a> is also well-known but relatively inactive recently.</li>
  <li>GNU <a href="http://www.gnu.org/software/emacs/manual/html_node/emacs/index.html">Emacs Manual</a> and <a href="http://www.gnu.org/software/emacs/manual/html_node/elisp/">Emacs LISP Manual</a></li>
  <li><a href="http://batsov.com/articles/2012/02/19/package-management-in-emacs-the-good-the-bad-and-the-ugly/">Guidelines</a> for package management in Emacs.</li>
  <li><a href="http://www.emacswiki.org/emacs/">Emacs Wiki</a></li>
  <li><a href="http://www.masteringemacs.org/">Mastering Emacs</a></li>
</ul>

<p>–Well, it is really a road that will never end…</p>

<h3 id="packages">Packages:</h3>

<ul>
  <li><a href="https://github.com/magit/magit">Magit</a>. “Magit is the most popular interface to git. If you are new to git and do not need support for other vcs this is likely the package you should try first” – quoted from <a href="http://www.emacswiki.org/emacs/Git">EmacsWiki</a>. The detail explanation can be found from <a href="http://www.masteringemacs.org/articles/2013/12/06/introduction-magit-emacs-mode-git/">Mastering Emacs</a>.</li>
  <li><a href="http://company-mode.github.io/">Company</a> for auto-completion.</li>
</ul>

<h3 id="random-thoughts">Random Thoughts</h3>
<ul>
  <li>One of the most fundamental change from Vim to Emacs is that Vim is the most powerful editor in this planet while Emacs is kind of <a href="http://c2.com/cgi/wiki?EmacsAsOperatingSystem">“operating system” with a lousy editor</a>. It might be a rant to the right place, but anyway, the other side of the story is that emacs can be regarded as an OS which means that it might be much more powerful when the configuration is right. I should be able to do things that are used to complete via the combination of vim, shell, REPL, and compiler, and I SHOULD NOT launch and exit it very often as what I am doing with vim.</li>
  <li>Everything looks a little bit more decent within the emacs,
including the shell.</li>
</ul>

<h3 id="useful-key-combinings">Useful Key Combinings:</h3>

<p>Kill a line:
C-a C-k (move the cursor to the begining of the line, thenkill from the cursor to the end of the line)</p>

<p>Kill 2 lines: C-a C-u 2 C-k</p>

<p>Kill a specific region
C-&lt;SPC&gt; C-w (move around to highlight region, then kill contents within highlight region)</p>

<p>Yank the killed contents C-y</p>

<p>Retrieve yanking history
M-y (right after the 1st yanking. – this is intersting)</p>

<p>The difference between “killing” and “deleting” is that “killed” text
can be reinserted (at any position), whereas “deleted” things cannot
be reinserted in this way (you can, however, undo a deletion–see below).
Reinsertion of killed text is called “yanking”.  Generally, the
commands that can remove a lot of text kill the text (they are set up so
that you can yank the text), while the commands that remove just one
character, or only remove blank lines and spaces, do deletion (so you
cannot yank that text).  &lt;DEL&gt; and C-d do deletion in the simplest
case, with no argument.  When given an argument, they kill instead.
– This is valid for both vim and emacs.</p>

<p>Scoll down the page
C-v (page down)
C-u 8 C-v (scoll down 8 lines)
C-l (move the current line to the middle of the window)
C-u 0 C-l (move the current line to the head of the window)</p>

<p>Getting help
C-h c &lt;Command sequence&gt;   (a very brief description of the command.)
C-h k &lt;Command sequence&gt;   (displays the documentation of the function, as well as its name)</p>

<p>Auto-completion
M-/
<a href="http://company-mode.github.io/">Company</a> is good complementory plug-in</p>

<p>Shell History (also Useful for Haskell REPL)
M-p (or) C-&lt;UP&gt;: Fetch the next earlier old shell command.
M-n (or) C-&lt;DOWN&gt;: Fetch the next later old shell command.
M-r: Begin an incremental regexp search of old shell commands.
C-c C-x: Fetch the next subsequent command from the history.
C-c . : Fetch one argument from an old shell command.
C-c C-l: Display the buffer’s history of shell commands in another window (comint-dynamic-list-input-ring).</p>

<h3 id="missing-features">Missing Features:</h3>

<p>This is a list for what I should expand the functionalities of my Emacs.</p>

<ul>
  <li>Highlight symbol at the point. There is <a href="http://www.emacswiki.org/emacs/HighlightSymbol">a package</a> for this purpose, but currently it does not work well within Prelude.</li>
  <li>Interactive input for M-x.</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My 2013 and new year resolution]]></title>
    <link href="http://creasyw.github.io/blog/2013/12/31/my-2013-and-new-year-resolution/"/>
    <updated>2013-12-31T10:13:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2013/12/31/my-2013-and-new-year-resolution</id>
    <content type="html"><![CDATA[<p>没有想到，这一年能发生这么多的事情。效率从年初开始，越来越高。然后是暑假实习，认识了很多有趣的人，开始打网球。去了波多黎各和维京群岛，看到一生迄今为止最蓝的海。回来后继续打网球，开始瘦身，失散了三十年的六块腹肌和人鱼线都找到了，可年末却把豆豆丢了。痛彻心扉的最后两个月，不太清楚自己是怎么度过的。</p>

<h3 id="statistics">Statistics:</h3>

<p>过去的一年，在学校里修了两门课，GPA还是4.0。发表了三篇文章，还有三篇在等消息，两篇在写，为IEEE Trans. of Signal Processing 和ICC2014 审了两篇论文。此外，在Coursera上完成了6门课，其中收获最大的有Dan Grossman 的Programming Language 以及Tim Roughgarden 的Algorithm Analysis I &amp; II。比较可惜的是Andrew Ng 的 Machine Learning，课程和作业都过半了，但因为自己的论文进度太紧，这门课最终还是没能完成。希望它来年还能再开。</p>

<p>根据豆瓣上的统计，这一年我看完19本书，听了27盘专辑，看了50部电影。其中看过最好看的书是现在还没有读完的巨著SICP…好看的电影包括Argo, The Social Network, Now You See Me, and Star Trek Into Darkness；听歌因为大量使用Douban FM 和Pandora，已经无法具体记录了。另外，完成了2325小时的编程。从九月到年底，用nike running 跑了110 miles，越跑越快，从九月份的7’36”/mi 到十二月的6’47”/mi。体重从78公斤降低到现在的68公斤，腹部和手臂的肌肉都清晰可见了。还有很多东西没有量化，比如网球的一发成功率，主动得分，以及非受迫性失误，等等。</p>

<h3 id="programming">Programming:</h3>

<p>在Coursera上的几门课程对我帮助很大，从熟悉新的编程语言，到高屋建瓴的指导如何实践。这一年新学的语言包括ML, Scala, Ruby, and Haskell，其中前三个都是课程里涉及的。编程时间的积累已经过半，到了5750小时。从简历上，我可以堆出一大坨熟练使用的语言。而对自己而言，进步最大的有两方面。其一，现在可以用很短的时间，甚至是一个下午，去学习一门新的编程语言，其实只用熟悉常用的语法就好，其中的范式和思想都是共通的。其二，对于算法和数据结构的掌握，让我能在更短的时间里将一个具体问题转变成模型。</p>

<p>这一年也花了大量的时间写C++代码，实习里用到了，自己的项目也用到了。但写来写去，依然不喜欢这个语言——繁琐，庞大高效，想做所有的事情却鲜有亮点。用Jobs描述微软的词语来形容C++也是合适的，no taste。使用它，仅仅是因为所处状况暂时没有其他选择而已。在2014年里，计划将实验室的项目逐渐向Haskell过渡，当必须使用OOP的时候，用Scala。至于继续提高的方向，暂时还没想到什么新的语言特别值得学习(maybe Lua, R, or Javascript)，但需要花时间把Compiler看完，然后读完三本2013积攒下来的书：SICP, The Scheme Programming Language，和Real World Haskell。若是此外还有空余，可以旁听一下iOS的课程，重温一下已经放下两年的Obj-C。</p>

<p>因为Haskell的缘故，这几个月越来越多的使用Emacs。发觉一个有关它的笑话大体是对的，Emacs的启动时间都足够用Vim写完一个脚本了。当然，依此类推，启动Eclipse都足够写完一个项目了。。。现在我主要还是是把Emacs当Vim来用，除了C-c C-l来加载Haskell的Compiler，我只不过是在使用Vim里对应的快捷键组合来写程序。我也知道，有关Emacs最吸引人的.el 脚本，我还没有过多涉及。希望在接下来的一年里，我能像使用Vim一样熟练的使用Emacs，有一套自己的加载脚本，多一个得心应手的开发工具。</p>

<h3 id="sth-else">Sth. else</h3>
<ul>
  <li>每周锻炼3-4次</li>
  <li>晋级 Tennis Recreation League 3.5</li>
  <li>累积2500+小时的编程</li>
  <li>毕业</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[LTE reading excerpt]]></title>
    <link href="http://creasyw.github.io/blog/2013/10/09/lte-reading-excerpt/"/>
    <updated>2013-10-09T18:21:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2013/10/09/lte-reading-excerpt</id>
    <content type="html"><![CDATA[<p>The LTE-Advanced introduced by LTE standard release 10 has many new features, including the carrier aggregation, enhanced intercell interferernce coordination (ICIC) for heterogeneous networks (HetNets), enhanced multiple-antenna transmission supporting up to eight downlink layers, and relaying and coordinated multipoint (CoMP) transmission.</p>

<p>For the carrier aggregation, in order to fully compliant with the IMT-Advanced requirements, the radio-access technology in LTE-Advanced does not only provide entensive support for deployment in spectrum allocations with bandwides ranging from 1 MHz to 20 MHz for backwards compatibility, but also extends by means of carrier aggregation, where multiple component carriers are aggregated and jointly used for transmission to/from a signle terminal. Up to five component carriers, possibly each of different bandwidth, can be aggregated, allowing for transmission bandwidth up to 100 MHz. The component carriers that a UE needs to support are determined through a UE-specific configuration process and a dynamic activation and deactivation process. Due to this activation/deactivation process, the state of SCells can be changed frequently. As a result, <strong>radio link monitoring is only supported in the PCell but not in SCells to avoid complex UE behavior and additional control signaling overhead. Despite this kind of effort, the increased complexity due to physical downlink control channel (PDCCH) decoding and timing tracking of multiple component carriers cannot be avoided</strong>. </p>

<p>The receiver RF filter design depends on the type of carrier aggregation. For the interest of low hardware complexity, a singular RF chain is preferable. But it requires an analog-to-digital converter and RF filter with larger bandwidth. Moreover, due to activation and deactivation of component carriers, there is a retuning issue when a single RF is used for these component carriers. <strong>There should be techniques balancing the packet loss due to RF retuning and the measurement of deactivated SCells to achieve optimal network performance</strong>.</p>

<p>A HetNet consists of low-power picocells and femtocells in addition to high-power macrocells to improve end-users QoS. But this benefit comes at the cost of additional intercell interference between heterogeneous cells, and some of the femtocells might be closed subscriber group, which make the strongest downlink power at the viewpoint of certain UE be the interference. Besides, the commeon reference signal (CRS), synchronization signals, and physical broadcast channel (PBCH) are transmitted in almost blank subframe (ABS), which cause the collision among different Scells. **The interference cancellation should developed based on the release 8/9 which soly considers the macrocell interference management through ABS.</p>

<p>The LTE-Advanced system should fulfill the ITU requirements of the downlink peak spectral efficiency of 30 b/s/Hz. The peak spectral efficiency is the highest achievable data rate per overall cell bandwidth assuming error-free conditions when all available radio resources for the corresponding link direction are assigned to a single UE unit. While two- or four-layer transmission would be more prevalent even for the LTE-Advanced system, the required downlink peak spectral efficiency can only be attained using high-order antenna configurations (i.e., 8 × 8). <strong>The main challenge of high-order multiple-input multiple-output (MIMO) is computational complexity</strong>. Maximum likelihood (ML) detection is optimal in the sense that it minimizes error probability when the distributions of all data are equally likely. However, due to its high complexity in 8×8 MIMO systems with high modulation order, a direct implementation of ML detection might not be a viable option for such MIMO systems.</p>

<p>The alternatives are zero-forcing (ZF) and minimum mean square error (MMSE) detection, but both of them are much worse in performance compared with ML. The k-best detection is another choice, but although its performance is close to ML, its computational complexity is still high to be implemented in the real-world multi-antennas configurations.</p>

<p>In the UE, channel estimation is for feeding back channel state information (CSI) to the base station and equalization of the downlink channel in the process of data demodulation. One of the requirements for LTE-Advanced is that it should support up to eight-layer transmission, which implies that there need to be at least eight transmit antenna ports. Toward this, a key change in the reference signal design philosophy from LTE Release 8 is the separation of the demodulation reference signals (DM-RS) from the channel state information reference signals (CSI-RS) in Release 10. The up-side is saving significant reference signal overhead since it allows the densely populated DM-RS to be UE-specific. The down-side is that in order to provide for eight CSI-RS patterns, the density of CSI-RS in LTE-Advanced is significantly less than that of CRS, that is, there is only one CSI-RS resource element (RE) per RB per antenna port. Besides, CSI-RS is expected to be transmitted only once every five or ten sub-frames. <strong>Advanced algorithms are needed for CSI-RS-based channel estimation and computation of the CSI feedback parameters such as CQI (i.e., modulation and coding rate) because existing methods may incur throughput degradation and/or result in a failure to meet the target BLER requirements.</strong> Possible strategies to improve the CSI-RS channel estimation performance could include exploitation of the time-frequency correlations, the channel’s power delay profile (PDP) and the Doppler shift. </p>

<p>[1] S. Parkvall, A. Furuskär, and E. Dahlman, “Evolution of LTE Toward IMT-Advanced,” <em>IEEE Commun. Mag.</em>, vol. 49, no. 2, pp. 84-91, Feb, 2011.<br />
[2] D. Bai, C. Park, J. Lee, and H. Nguyen, “LTE-advanced modem design: challenges and perspectives,” <em>IEEE Commun. Mag.</em>, vol. 50, no. 2, pp. 178-186, Feb. 2012.<br />
[3] E. Dahlman, S. Parkvall, and J. Sköld, <em>4G LTE/LTE-Advanced for Mobile Broadband</em>, Academic Press, 2011.<br />
[4] Z. Guo and P. Nilsson, “Algorithm and Implementation of the K-Best Sphere Decoding for MIMO Detection,” <em>IEEE JSAC</em>, vol. 24, no. 3, Mar. 2006, pp. 491–503.<br />
[5] M. Baker, <a href="http://www.3gpp.org/ftp/workshop/2009-12-17_ITU-R_IMT-Adv_eval/docs/pdf/REV-090003-r1.pdf">LTE Advanced Physical Layer</a>. <br />
[6] J. Wannstrom, <a href="http://www.3gpp.org/IMG/pdf/lte_advanced_v2.pdf">Introduction to LTE-Advanced</a>.   </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[All-pairs shortest path]]></title>
    <link href="http://creasyw.github.io/blog/2013/09/30/johnsons-algorithm/"/>
    <updated>2013-09-30T23:49:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2013/09/30/johnsons-algorithm</id>
    <content type="html"><![CDATA[<p>The question comes from the online course <em>Algorithm Design and Analysis (Part II)</em> in coursera. It is an <a href="http://en.wikipedia.org/wiki/Shortest_path_problem#All-pairs_shortest_paths">all-pairs shortest path problem</a>. As mentioned in the wikipedia, a more straightforward solution with Floyd–Warshall algorithm takes \(O(N^3)\) complexity, and the more computational efficient approach is to use a combination of Dijkstra’s algorithm, Bellman-Ford algorithm, and Johnson’s algorithm, which chould decrease the complexity to \(O(N^2logN)\). I implement the latter one for more interesting and challenging. There are several obstacles make the implementation a little bit trickier than I thought.</p>

<p>I have tried two or three different versions of Dijkstra’s algorithm while solving other math puzzles, and this time I use the built-in heapq function in Python. Keeping the “about-to explore” nodes in order and extracting the smallest/largest cost one in every iteration are the essense of this algorithm. But the cost to every node has to be updated when a node moves from “about-to explore” to “fully explored” category. At first, I just remove the original value and push the updated one into the heap. Because the heapq has no updated or remove methods, I can only use the remove mehtod of the list. This works fine for small amount of nodes (200) but the heap cannot keep right struture when the data becomes just a little bigger (500). Then I have to <em>heapify</em> it every time I update a “about-to explore” node.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>Dijkstra&#8217;s Algorithm</span><a href="https://github.com/creasyw/learning/blob/master/courses/algo_analysis_II/hw4/dijkstras.py">link</a></figcaption> <div class="CodeRay">
  <div class="code"><pre>
<span class="keyword">def</span> <span class="function">dijkstras</span>(graph, start):
    <span class="comment"># keep a record of the distance of the nodes from the start vertex</span>
    distance = defaultdict()
    <span class="comment"># keep track of the candidates for the next move</span>
    index = defaultdict()
    <span class="comment"># store the cost and node into heap using cost as the key</span>
    heap = []
    heapq.heapify(heap)
    <span class="comment">#will be used to trace the path of the sjortest distance to each node</span>
    distance[start] = <span class="integer">0</span>
    <span class="keyword">if</span> start <span class="keyword">in</span> graph <span class="keyword">and</span> <span class="predefined">type</span>(graph[start])==<span class="predefined">dict</span>:
        <span class="keyword">for</span> (node, cost) <span class="keyword">in</span> graph[start].items():
            heap_update(heap, index, node, cost)
    <span class="keyword">else</span>:
        <span class="keyword">return</span> distance
    <span class="comment">#initially all nodes are yet to be explored</span>
    <span class="keyword">while</span> <span class="predefined">len</span>(index) &gt; <span class="integer">0</span>:
        <span class="comment"># need to extract the node with the minimum path</span>
        node, cost = heap_pop(heap, index)
        <span class="comment"># store the node into known graph</span>
        distance[node] = cost
        <span class="comment"># update the knowledge according to existing node</span>
        <span class="keyword">if</span> node <span class="keyword">in</span> graph <span class="keyword">and</span> <span class="predefined">type</span>(graph[node])==<span class="predefined">dict</span>:
            <span class="keyword">for</span> (node, localcost) <span class="keyword">in</span> graph[node].items():
                <span class="keyword">if</span> node <span class="keyword">not</span> <span class="keyword">in</span> distance:
                    heap_update(heap, index, node, localcost+cost)
    <span class="keyword">return</span> distance
</pre></div>
</div>
 </figure></notextile></div>

<p>The Bellman-Ford algorithm is more expensive compared with Dijkstra’s algirhtm if the graph is densily connected, but it deals with negative edge cost. This is also the one that helps me fully appreciate the dynamic programming.The implementation is intuitive and straightforward. For every vertex, the brutal force search performs to find the current optimal solution based on the previous knowledge. The optimization for space complexity is to only store the most recent result–keep an 2*N array and use a pointer filp-flop in every iteration is more effecient than keeping two 1*N array, discarding the older one and reclaiming a new one in every iteration. Aother optimization I make is to store the “about-to explore” nodes in a bucket, just as what Dijkstra’s does, which eliminates plenty of unnecessary calculation. But its tricky aspect is that because this algorithm is computing “distributed”, different from the “centralized” spanning of Dijkstra’s, if several “exploring” vertices point to a same “about-to explore” vertex, only the optimal cost should be kept.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>Bellman-Ford Algorithm</span><a href="https://github.com/creasyw/learning/blob/master/courses/algo_analysis_II/hw4/bellman_ford.py">link</a></figcaption> <div class="CodeRay">
  <div class="code"><pre>
<span class="keyword">def</span> <span class="function">bellman_ford</span> (arr, start, size):
    <span class="docstring"><span class="delimiter">&quot;&quot;&quot;</span><span class="content"> The input arr stores all info of the graph in a dictionary.</span><span class="content">
</span><span class="content">        The basic element in the arr are three-columns data -- </span><span class="content">
</span><span class="content">        [start_point, end_point, cost]</span><span class="delimiter">&quot;&quot;&quot;</span></span>
    count = <span class="integer">1</span>
    data = np.zeros((<span class="integer">2</span>, size+<span class="integer">1</span>))
    <span class="comment"># initialization</span>
    data.fill(<span class="predefined">float</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">inf</span><span class="delimiter">&quot;</span></span>))
    data[<span class="integer">0</span>, start] = <span class="integer">0</span>
    bucket = {}
    <span class="keyword">for</span> i <span class="keyword">in</span> arr[start]:
        bucket[i] = {start:arr[start][i]}
    
    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="predefined">range</span>(<span class="integer">1</span>, size):
        <span class="comment"># use set() to make sure start points in the next round are unique</span>
        candidate = <span class="predefined">set</span>()
        previous = count ^ <span class="integer">1</span>
        data[count] = data[previous]
        <span class="keyword">for</span> v <span class="keyword">in</span> bucket:
            data[count, v] = <span class="predefined">min</span>(data[previous, v], \
                data[previous, bucket[v].keys()[<span class="integer">0</span>]] \
                +bucket[v].values()[<span class="integer">0</span>])
            candidate.add(v)
        <span class="comment"># stop early if there is no place to span</span>
        <span class="keyword">if</span> (data[count]==data[previous]).all():
            <span class="keyword">break</span>
        <span class="comment"># update the bucket</span>
        bucket = {}
        <span class="keyword">for</span> j <span class="keyword">in</span> candidate:
            <span class="keyword">for</span> k <span class="keyword">in</span> arr[j]:
                <span class="keyword">if</span> (k <span class="keyword">in</span> bucket <span class="keyword">and</span> data[count,j]+arr[j][k] &lt; \
                      data[count, bucket[k].keys()[<span class="integer">0</span>]] + \
                      bucket[k].values()[<span class="integer">0</span>]) <span class="keyword">or</span> k <span class="keyword">not</span> <span class="keyword">in</span> bucket:
                    bucket[k] = {}
                    bucket[k][j] = arr[j][k]
        <span class="keyword">if</span> <span class="keyword">not</span> bucket:
            <span class="keyword">break</span>
        count = previous
    
    <span class="comment"># check cycle with negative sum</span>
    previous = count ^ <span class="integer">1</span>
    data[count] = data[previous]
    <span class="keyword">for</span> v <span class="keyword">in</span> bucket:
        data[count, v] = <span class="predefined">min</span>(data[previous,v], \
                data[previous, bucket[v].keys()[<span class="integer">0</span>]]+bucket[v].values()[<span class="integer">0</span>])
    <span class="keyword">if</span> (data[count]== data[previous]).all():
        <span class="keyword">return</span> data[count]
    <span class="keyword">else</span>:
        <span class="keyword">return</span> <span class="predefined">float</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">inf</span><span class="delimiter">&quot;</span></span>)
</pre></div>
</div>
 </figure></notextile></div>

<p>Finally, the two algorithms above are connected by the Johnson’s algorithm. Dijkstra’s algorithm cannot deal with negative edge costs, but much more fast than Bellman-Ford especially in the case of “all-pairs”. Furthermore, the negative costs cannot be got rid of by adding uniformly for every edge. Johnson’s algorithm neatly solves it by adding pseudo-node to find weights of vertices and changing values of edges concerning their connected vertices. There is no hidden obstacle in the implementation. Only the special care should be taken for manipulating the nodes. It reminds me coding in C…</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption class="code-header" style="margin-bottom:-5px;"><span>Johnson&#8217;s Algorithm</span><a href="https://github.com/creasyw/learning/blob/master/courses/algo_analysis_II/hw4/johnsons.py">link</a></figcaption> <div class="CodeRay">
  <div class="code"><pre>
<span class="keyword">def</span> <span class="function">johonsons</span>(data, vertex):
    d1 = data.copy()
    <span class="comment"># make psedu node pointing to all other nodes with zero cost</span>
    plus1 = vertex+<span class="integer">1</span>
    d1[plus1] = {}
    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="predefined">range</span>(<span class="integer">1</span>, plus1):
        d1[plus1][i] = <span class="integer">0</span>
    <span class="comment"># calculate the reweight vector</span>
    reweight = bellman_ford(d1, plus1, plus1)
    <span class="comment"># reweight all cost to make it nonnegative</span>
    <span class="keyword">if</span> <span class="predefined">type</span>(reweight) == <span class="predefined">float</span>:
        <span class="comment"># stop if there is any negative cycle in the graph</span>
        <span class="keyword">return</span> <span class="predefined-constant">None</span>
    <span class="keyword">else</span>:
        <span class="keyword">for</span> i <span class="keyword">in</span> data:
            <span class="keyword">for</span> k <span class="keyword">in</span> data[i]:
                data[i][k] = data[i][k]+reweight[i]-reweight[k]
    
    <span class="keyword">return</span> [<span class="predefined">min</span>(reconvert(reweight,vertex,dijkstras(data,i),i))\
            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="predefined">range</span>(<span class="integer">1</span>,vertex+<span class="integer">1</span>)]
</pre></div>
</div>
 </figure></notextile></div>

<p>The overall algorithm solves the question and runs kind of standard. Still, I do not satisfy with the update procedure of heap. I will write a new version of this data structure in the near future and see if it can provide significant boost for the performance.</p>

<p>p.s. The vistualization of code block is optimized from the original Octopress style to Github-style based on the <a href="http://blog.codebykat.com/2013/05/23/gorgeous-octopress-codeblocks-with-coderay/">tutorial</a>.<br />
p.p.s. The inline latex-style formula comes with Kramdown, MathJax and <a href="http://yoyzhou.github.io/blog/2012/08/05/add-latex-support-for-octopress/">this tutorial</a>. Besides, there is <a href="http://brianbuccola.github.io/blog/2012-11-28-latex-math-in-octopress.html">another minor bug to deal with</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[More freedom in doing things]]></title>
    <link href="http://creasyw.github.io/blog/2013/08/15/more-freedom-in-doing-things/"/>
    <updated>2013-08-15T00:15:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2013/08/15/more-freedom-in-doing-things</id>
    <content type="html"><![CDATA[<p>I heard lots of opinions from both Mac lovers and haters before I bought my macbook pro. It made me struggle for a while to leverage the pros and cons. But it finally turned out neither of them was completely right. I love my mbp very much, but the reason is not the good looking, but the flexibility interacting with unix programs and great ease using homebrew for almost all dependent packages. Besides, if I was not forced using Windows OS again in my internship, I would not notice how ugly and inconvenient it is.</p>

<p>The same process happened once again when I met latex. The final result was that I fell in love with it, and found out no one gave me a comprehensive description about it before.</p>

<p>LaTeX is more about higher-level accessing Tex for formating and typesetting. That is it. The focus for writing, the ease of math formulas, and even the licensing advantage over MS are all derivatives from others personal experiences. Actually, the basic intention gives it the most attractive feature. First of all, setting up a general framework, then maybe another subset of framework. The framework is at will, but everything fell into it must follow the specific rules. Then, beyond the framework, or within the framework, everything is also at will. One can freely design all specifications, and if needed, one can also overwrite the general rules set by the framework. On the one hand, the environment setting let author get rid of all trivial concerns. On the other hand, in every place, one can regain the control of everything. LaTeX is not only for writing, it is for programming.</p>

<p>Then, several days ago, I was trying to transfer my blog from Blogger to Jekyll. It is a static site generator that takes Markdown blog posts and onverts them into html files. The benefits are attractive: the website can be hosted by almost any server; the whole blog can easily be version controlled, since no php or MySQL needed, it requires less maintainance. During playing with it, I have the same kind of feeling again. I might easily mess everything up while on the other hand I have fully control of every element in the page.</p>

<p>I cannot build it without kind-hearted help from others. Especially,</p>

<ul>
  <li><a href="https://github.com/yanga9">Alex Yang</a>, who designs this theme. I really like the succinct layout and the Hello page. His comprehensive introductory email also saved me lots of time and gave me solid understanding of how jekyll and octopress work.</li>
  <li><a href="http://octopress.org/docs/setup/">Octopress: Getting started</a> and an <a href="http://labs.grupow.com/blog/2012/01/30/start-blogging-with-octopress">alternative post</a>. Provide fool-proof tutorials of setting things up. For the latter post, there is no need to insall Pow. The “rake preview” will get the result with <a href="http://stackoverflow.com/questions/17465404/rake-preview-not-working-in-octopress">one precaution</a>.</li>
  <li><a href="https://gist.github.com/juniorz/1564581">Import from Blogger</a>. This script was found from Jekyll official site.</li>
  <li><a href="http://conghui.github.io/2013/04/27/did-not-find-expected-key-while-parsing-a-block-mapping/">Rake Generate issue caused by double quotes</a>. The script above cannot well handle double quotes, which will cause problem when generating yaml. Here is the solution.</li>
</ul>

<p>Of course, there are some other things that I tried and failed to like. C++ might be an example… =P Anyway, my point is, regardless what other people say, you will never know what a thing really is unless you actually do it. There is one ultimate goal for a given project, and at least one suitable path to get there. Just do it. Then in retrospect, we will know if it is a better option, and will perform better the next time.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Reading note of SICP (4)]]></title>
    <link href="http://creasyw.github.io/blog/2013/08/10/reading-note-of-sicp-4/"/>
    <updated>2013-08-10T00:00:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2013/08/10/reading-note-of-sicp-4</id>
    <content type="html"><![CDATA[<div class='post'>
  Aug. 10th. Complete the 1st chapter of sicp.<br/><br/>
  
  I really appreciate the exercises within each subsections, because I can feel that they are well designed. I used to have the same feeling when I did the homework from Dan&#8217;s course of programming languages. The exercises make the general concepts concrete and doable.
  <br/><br/>
  The abstraction is far from merely making the code more structured and readable. It is a design choice. Sometimes, it takes experience to find out where should be abstracted. And sometimes, it takes much more endeavors than simply mix everything together. But once the choice of abstraction is right, the program becomes clearer, and it increases many degrees of freedom for the design afterwards.</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Reading note of SICP (3)]]></title>
    <link href="http://creasyw.github.io/blog/2013/08/08/reading-note-of-sicp-3/"/>
    <updated>2013-08-08T00:00:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2013/08/08/reading-note-of-sicp-3</id>
    <content type="html"><![CDATA[<div class='post'>
&nbsp;<br />At the end of the 1st chapter, it enumerates the basic reason for the powerful lisp: first-order procedure.<br /><br />The major &#8220;privileges&#8221; of the first-order elements are:<br />1) They may be named by variables.<br />2) They may be passed as arguments to procedures.<br />3) They may be returned as the results of procedures.<br />4) They may be included in data structures.<br />They can be crucial abstraction mechanism permitting to express the general methods of computing as explicit elements in programming language, so that they can be handled just like other computational elements. The expression power is enormous.<br /><br />I have already been used to use the first two kinds of procedures, but the last two actually make the program even more expressive and powerful. Those are also the attractive properties sharing among functional programming languages.</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Reading note of SICP (2)]]></title>
    <link href="http://creasyw.github.io/blog/2013/08/07/reading-note-of-sicp-2/"/>
    <updated>2013-08-07T00:00:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2013/08/07/reading-note-of-sicp-2</id>
    <content type="html"><![CDATA[<div class='post'>
<br />While I am reading, I always try to distinguish which part of thoughts I used to learn from here when I read it for the first time, and which part I learned from Dan&#8217;s course. And, surprisingly enough, I learned almost all basic factors from Dan, though I always felt I learned a lot of things last year when I began to read it.<br /><br />The name of this book is perfect for the content &#8211; Structure and Interpretation of Computer Programs. It does not teach about how to program, nor a specific programming language. Of course it is a legacy book. But it seems to me that I cannot get enough from this book unless I have mastered quite a few programming languages. After Dan taught me everything about basic aspects of programming languages and I played with Ruby and Racket for a long time, even after I leaned all those &#8220;nontrivial&#8221; trivial things about C++, when I read it now, I am able to distinguish which part is the essence and which part is written just for the ease of learning, and I can fully focus on how to put different abstractions into different layers&#8211; in other words, learning the structure and interpretation of computer programs.<br /><br />I read a comment, saying that Chapter 4 and 5 are the essence of the book. Hopefully, I can finish reading it before September, and leave enough time for Design Patterns.</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Reading note of SICP]]></title>
    <link href="http://creasyw.github.io/blog/2013/08/06/reading-digest-sicp/"/>
    <updated>2013-08-06T00:00:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2013/08/06/reading-digest-sicp</id>
    <content type="html"><![CDATA[<div class='post'>
P59. I still don&#8217;t think it is necessary to use &#8220;square&#8221; instead of (* x x) everywhere we perform this operation, but I appreciate the idea of &#8220;abstraction&#8221;. It is really a good idea (and practice) to abstract concepts in different levels and use them accordingly.<br /><br />Most of the examples I read are in a top-down design manner: firstly use the abstract concepts, and then implement it in a lower level. The concerns for specific lower-level modules is similar to the way I did using unit test. But I am a little bit confuse how to perform the unit test in this manner. Especially for the closure using in LISP&#8211;implementing local helper functions right after building major function&#8211; how can I make sure the helper functions are right before I run the program as a whole? If I separate a helper function as an independent one, it seems that quite a little redundant work has to perform when I move it back to the major function.<br /><br />Anyway, SICP just makes me love Racket even more =D<br /><br />cheers,</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python/Numpy version collisions]]></title>
    <link href="http://creasyw.github.io/blog/2013/07/23/pythonnumpy-version-collisions/"/>
    <updated>2013-07-23T00:00:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2013/07/23/pythonnumpy-version-collisions</id>
    <content type="html"><![CDATA[<p>Before this accident, I did not even know there were so many places relevant with a single program… I opened the pandora’s box beginning with using <code>brew doctor</code> which told me to move directory /usr/local/bin/ prior to /usr/bin/ so that all the homebrewed packages could be found automatically. After I did this, if I executed matplotlib, I would have this runtime error <code>RuntimeError: module compiled against API version 8 but this version of numpy is 6</code> which was somewhat correct by the way. Because I used superpack installed the latest version of numpy(1.8), scipy(0.13), and matplotlib(1.4), but if I printed out the “numpy.<strong>version</strong>” in a script, it showed 1.6.1.</p>

<p>Then I tried the following solution:  </p>

<ol>
  <li>delete all of the outdated versions of numpy</li>
  <li>make sure I explicitly add PYTHONPATH in the bash_profile.</li>
  <li>I even uninstalled and reinstalled the numpy<br />
But the problem was still there…</li>
</ol>

<p>After an exhausted search, I found that numpy-1.6.1 in<br />
<code>/System/Library/Frameworks/Python.framework/Versions/2.6/Extras/lib/python/ </code><br />
I still don’t know why it search into the directory of 2.6 given there is another 2.7 in the same level. Deleting both 2.6 and 2.7 directories (only delete the 2.6 could not work either…) finally solved the problem. ahooooo….</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setup emacs in Mac OS]]></title>
    <link href="http://creasyw.github.io/blog/2013/07/01/setup-emacs-in-mac-os/"/>
    <updated>2013-07-01T00:00:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2013/07/01/setup-emacs-in-mac-os</id>
    <content type="html"><![CDATA[<p>The setup is much harder than I thought…</p>

<p>1) using homebrew installs the emacs and guile. Then, I also need to add path in the .bash_profile to launch the up-to-date emacs rather than the original version 22.1 shipped with the os.<br />
<code>export PATH=/usr/local/Cellar/emacs/24.3/bin:$PATH</code></p>

<p>2) Enable the <a href="http://stackoverflow.com/questions/162896/emacs-on-mac-os-x-leopard-key-bindings">Meta key in terminal</a>, or similar position for iterm2.</p>

<p>After these two steps, the following is more straightforward.</p>

<p>3) I accidentally found this “<a href="https://github.com/technomancy/emacs-starter-kit">emacs-starter-kit</a>”, which had 2300+ stared and really saved my day. Just follow the instruction and everything will be fine.</p>

<p>In current state, I feel emacs kind of like vim+tmux. Anyway, learning new knowledge is always a pleasure, especially about this kind of “legacy” stuff.</p>

<p>cheers,</p>

<p>[UPDATE: after changed the loading sequence of bash in <code>/etc/paths/</code> the first step seems unnecessary… actually, that was something I should do as soon as I used homebrew to port packages. <a href="http://bit.ly/IUVl9a">http://bit.ly/IUVl9a</a>]</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[C++ rants (continued)]]></title>
    <link href="http://creasyw.github.io/blog/2013/06/05/c-rants-continued/"/>
    <updated>2013-06-05T00:00:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2013/06/05/c-rants-continued</id>
    <content type="html"><![CDATA[<div class='post'>
(<a href="http://www.realworldtech.com/forum/?threadid=104299&amp;curpostid=104196">link</a>)<br /><br />&gt;Care to write an explicit example of a deep problem? (Except memory management - you already mentioned garbage collection.)<br /><br />Concurrency, for example.<br /><br />My point being, that C++ adds absolutely nothing interesting.<br /><br />&gt;All right. Then why do you think C should have support for structures (struct {&#8230;})?<br /><br />That&#8217;s just singularly stupid.<br /><br />C is a good language. It&#8217;s complete enough (and yes, the ability to handle structured data is very much required for any serious language) to be supremely useful, while at the same time being quite simple.<br /><br />A language without structured data types would not be a powerful language the way C is. You do need data structures, and you need pointers (to both data and code) to be at all interesting.<br /><br />But where do you draw the line?<br /><br />I know that you as a C++ proponent you probably won&#8217;t really &#8220;get&#8221; this simple argument, but try:<br /><br />- read the K&amp;R book on C (the ANSI edition), and be enlightened.<br /><br />Notice how the language is basically described by one rather thin book. Readably.<br /><br />So what C does so well is to do that whole &#8220;make it as simple as you can, but no simpler&#8221;. And that is what makes it great. The language is powerful, yet fairly minimal.<br /><br />There really aren&#8217;t many features you could remove from the C language without crippling it. Sure, there&#8217;s<br />three different looping constructs, and you could make trivial (syntactic) changes to the language, but that&#8217;s<br />really not the point. The language is simple, but without being too simple.<br /><br />Now, that&#8217;s not what you always want. I understand very well why people want less system-oriented languages with more built-in functionality. As mentioned, support for both garbage collection and concurrency are quite real problems, and they are both things you can do in C, but that you cannot do well with library interfaces, which is how you normally would extend on C.<br /><br />And garbage collection and concurrency are way more than just syntactic extensions. You can still do them very badly, of course, so it&#8217;s not a trivial path to go down, and I&#8217;m not saying hat a language magically becomes &#8220;good&#8221; just from supporting one or the other.<br /><br />But again: C does what it does very well, and with a clarity of thought and design that is entirely and utterly lacking from C++.<br /><br />And yes, I happen to think that clarity of thought and design is a good thing. It&#8217;s why I liked UNIX, even though I was initially introduced to other things (VMS - ugh).<br /><br />C++ is a mess. There&#8217;s no design. It&#8217;s just &#8220;add crud on top of C&#8221;. And the crud isn&#8217;t even meaningful, much less does it have a design. It&#8217;s totally and utterly random.<br /><br />It started out random, now it&#8217;s randomness that gets added to by a committee.<br /><br />&gt;For example, namespaces and function overloading are *not*<br />&gt;useless. They *do* solve a real problem that C is incapable<br />&gt;of solving.<br /><br />You&#8217;re full of it.<br /><br />&gt;For example, if you want in your source code to define a<br />&gt;function called &#8220;connect&#8221; and you also want include<br />&gt;&#8221;sys/socket.h&#8221;, you cannot do that in C.<br /><br />So to prove how it&#8217;s not just a syntactic feature, you start talking about syntax?<br /><br />What drugs are you on?<br /><br />The name overloading is a total syntactic feature. In C, the way you fix your problem is by a totally trivial syntactic change: you call your function &#8220;my_connect()&#8221;.<br /><br />Wow. It&#8217;s like magic. I added three characters, and made your whole reason for the crap that is C++ go away.<br /><br />The thing is, the above is a really good example of why C++ is horrible, and why C is so simple.<br /><br />Yes, the C solution is really simple. It&#8217;s so simple that it looks downright stupid. But it&#8217;s actually so simple that it is smart because quite frankly, it&#8217;s a lot easier to get confused in C++ code, when the same function name means totally different due to overloading.<br /><br />Of course, you&#8217;re not &#8220;supposed&#8221; to overload things in confusing ways, but the thing is, just do what C does: just make your function names unique. It&#8217;s not that hard, and by avoiding the overloading mess, you make it a lot easier to search for (hey look! &#8220;grep -w my_connect&#8221; just works!), and you avoid ambiguity.<br /><br />(Same exact thing goes for your other example: just add a module prefix or have some other trivial naming rules for your functional split-up, and be happy)<br /><br />Linus<br /><div><br /></div></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[C++ rants]]></title>
    <link href="http://creasyw.github.io/blog/2013/06/05/c-rants/"/>
    <updated>2013-06-05T00:00:00-07:00</updated>
    <id>http://creasyw.github.io/blog/2013/06/05/c-rants</id>
    <content type="html"><![CDATA[<div class='post'>
By&nbsp;<span style="background-color: white; font-family: arial, sans-serif;">Linus Torvalds:</span><br /><br /><a href="http://thread.gmane.org/gmane.comp.version-control.git/57643/focus=57918">On Wed, 5 Sep 2007</a>, Dmitry Kakurin wrote:<br />&gt;<br />&gt; When I first looked at Git source code two things struck me as odd:<br />&gt;1. Pure C as opposed to C++. No idea why. Please don&#8217;t talk about portability,<br />&gt;it&#8217;s BS.<br /><br />*YOU* are full of bullshit.<br /><br />C++ is a horrible language. It&#8217;s made more horrible by the fact that a lot of substandard programmers use it, to the point where it&#8217;s much much easier to generate total and utter crap with it. Quite frankly, even if the choice of C were to do *nothing* but keep the C++ programmers out, that in itself would be a huge reason to use C.<br /><br />In other words: the choice of C is the only sane choice. I know Miles Bader jokingly said &#8220;to piss you off&#8221;, but it&#8217;s actually true. I&#8217;ve come to the conclusion that any programmer that would prefer the project to be in C++ over C is likely a programmer that I really *would* prefer to piss off, so that he doesn&#8217;t come and screw up any project I&#8217;m involved with.<br /><br />C++ leads to really really bad design choices. You invariably start using the &#8220;nice&#8221; library features of the language like STL and Boost and other total and utter crap, that may &#8220;help&#8221; you program, but causes:<br /><br />&nbsp;- infinite amounts of pain when they don&#8217;t work (and anybody who tells me that STL and especially Boost are stable and portable is just so full &nbsp;of BS that it&#8217;s not even funny)<br /><br />&nbsp;- inefficient abstracted programming models where two years down the road you notice that some abstraction wasn&#8217;t very efficient, but now all your code depends on all the nice object models around it, and you cannot fix it without rewriting your app.<br /><br />In other words, the only way to do good, efficient, and system-level and portable C++ ends up to limit yourself to all the things that are basically available in C. And limiting your project to C means that people don&#8217;t screw that up, and also means that you get a lot of programmers that do actually understand low-level issues and don&#8217;t screw things up with any idiotic &#8220;object model&#8221; crap.<br /><br />So I&#8217;m sorry, but for something like git, where efficiency was a primary objective, the &#8220;advantages&#8221; of C++ is just a huge mistake. The fact that we also piss off people who cannot see that is just a big additional<br />advantage.<br /><br />If you want a VCS that is written in C++, go play with Monotone. Really. They use a &#8220;real database&#8221;. They use &#8220;nice object-oriented libraries&#8221;. They use &#8220;nice C++ abstractions&#8221;. And quite frankly, as a result of all these design decisions that sound so appealing to some CS people, the end result is a horrible and unmaintainable mess.<br /><br />But I&#8217;m sure you&#8217;d like it more than git.<br /><br /><span class="Apple-tab-span" style="white-space: pre;">   </span>Linus<br /><br />=====<br /><br />Heath Provost (galvanash@hotmail.com) on 6/5/10 wrote:<br />&gt;<br />&gt;As for C++ exceptions - the same thing really applies here.<br />&gt;They are trying to write explicit code. Exceptions are the<br />&gt;poster child for implicit magic&#8230;<br /><br />Yes, exceptions is a good example. The Linux kernel actually does its own exception mechanism, exactly because that way we control what is going on (and do it much more targeted to the actual need in question while giving much better performance and avoiding the crazy unwinding issues).<br /><br />And I really do dislike C++. It&#8217;s a really bad language, in my opinion. It tries to solve all the wrong problems, and does not tackle the right ones. The things C++ &#8220;solves&#8221; are trivial things, almost purely syntactic extensions to C rather than fixing some true deep problem.<br /><br />(The C++ objects, templates and function overloading are all just syntactic sugar. And generally bad syntax at that. And C++ actually makes the C type system actively worse.)<br /><br />In non-systems programming, you should almost certainly use a language that offers garbage collection. That will possibly make a real difference in the complexity of your application. The C++ features? Largely useless, and just helps you screw up more.<br /><br />And in systems programming, you&#8217;re simply better off with C. You&#8217;ll have a way easier time using all the existing code and libraries out there (re-using C++ code? Good luck). Fewer headaches, fewer opportunities to mess up the design and pick some unstable template library.<br /><br />So in neither case is C++ likely the right choice.<br /><br />Linus<br /><br /><br /></div>
]]></content>
  </entry>
  
</feed>
