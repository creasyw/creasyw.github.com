<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Programming | Qiong Wu]]></title>
  <link href="http://creasyw.github.io/blog/categories/programming/atom.xml" rel="self"/>
  <link href="http://creasyw.github.io/"/>
  <updated>2014-01-16T17:19:38-06:00</updated>
  <id>http://creasyw.github.io/</id>
  <author>
    <name><![CDATA[Qiong Wu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Emacs Progression Path]]></title>
    <link href="http://creasyw.github.io/blog/2014/01/02/emacs-progression-path/"/>
    <updated>2014-01-02T16:37:00-06:00</updated>
    <id>http://creasyw.github.io/blog/2014/01/02/emacs-progression-path</id>
    <content type="html"><![CDATA[<p>I’m kind of hoping to find something like <a href="http://stackoverflow.com/questions/2573135/python-progression-path-from-apprentice-to-guru">Python Progression Path</a> or sort of “best practice” when I am learning Emacs, since the difference between Vim and Emacs is much larger than I thought. But what I found via Google are either for really rookie teaching about basic operations such as saving and quiting the editor, or for only advanced player talking about using Emacs LISP…</p>

<p>Well, as a Vim user for roughly ten years, I will try to sort the contents of this post as an incremental record simulating my Emacs learning process, as well as keeping track of nontrivial materials and thoughts.</p>

<h3 id="resources">Resources:</h3>

<ul>
  <li><a href="http://sachachua.com/blog/2013/05/how-to-learn-emacs-a-hand-drawn-one-pager-for-beginners/">Tow</a> <a href="http://sachachua.com/p/26006">pics</a> served as the very beginning of entering the world of Emacs.</li>
  <li>Cheat Sheet (<a href="http://refcards.com/docs/gildeas/gnu-emacs/emacs-refcard-a4.pdf">compact version</a>, and <a href="http://cs.iupui.edu/~kweimer/EmacsCheatSheet.pdf">a more user friendly verion</a>).</li>
  <li>C-h t. Tutorial of Emacs within the editor. It should be the first doc to read.</li>
  <li>My previous <a href="http://wqiong.com/blog/2013/07/01/setup-emacs-in-mac-os/">post</a> to setup Emacs in Mac OS.</li>
  <li>Steve Yegge’s suggestion for <a href="https://sites.google.com/site/steveyegge2/effective-emacs">improving productivity with Emacs</a></li>
  <li>The <a href="https://github.com/xiaohanyu/oh-my-emacs">emacs enrionment</a> built by one of my friends.</li>
  <li><a href="http://batsov.com/prelude/">Prelude</a>. –haven’t tried that yet.</li>
  <li>GNU <a href="http://www.gnu.org/software/emacs/manual/html_node/emacs/index.html">Emacs Manual</a> and <a href="http://www.gnu.org/software/emacs/manual/html_node/elisp/">Emacs LISP Manual</a></li>
  <li><a href="http://www.emacswiki.org/emacs/">Emacs Wiki</a></li>
</ul>

<p>–Well, it is really a road that will never end…</p>

<h3 id="useful-key-combinings">Useful Key Combinings:</h3>

<p>Kill a line:<br />
C-a C-k (move the cursor to the begining of the line, thenkill from the cursor to the end of the line)</p>

<p>Kill 2 lines: C-a C-u 2 C-k</p>

<p>Kill a specific region<br />
C-&lt;SPC&gt; C-w (move around to highlight region, then kill contents within highlight region)</p>

<p>Yank the killed contents C-y</p>

<p>Retrieve yanking history<br />
M-y (right after the 1st yanking. – this is intersting)</p>

<p>The difference between “killing” and “deleting” is that “killed” text
can be reinserted (at any position), whereas “deleted” things cannot
be reinserted in this way (you can, however, undo a deletion–see below).
Reinsertion of killed text is called “yanking”.  Generally, the
commands that can remove a lot of text kill the text (they are set up so
that you can yank the text), while the commands that remove just one
character, or only remove blank lines and spaces, do deletion (so you
cannot yank that text).  &lt;DEL&gt; and C-d do deletion in the simplest
case, with no argument.  When given an argument, they kill instead.
– This is valid for both vim and emacs.</p>

<p>Scoll down the page<br />
C-v (page down)<br />
C-u 8 C-v (scoll down 8 lines)<br />
C-l (move the current line to the middle of the window)<br />
C-u 0 C-l (move the current line to the head of the window)  </p>

<p>Getting help<br />
C-h c &lt;Command sequence&gt;   (a very brief description of the command.)<br />
C-h k &lt;Command sequence&gt;   (displays the documentation of the function, as well as its name)</p>

<p>Auto-completion<br />
M-/<br />
<a href="http://company-mode.github.io/">Company</a> is good complementory plug-in</p>

<p>Shell History (also Useful for Haskell REPL)<br />
M-p (or) C-<up>: Fetch the next earlier old shell command.      
M-n (or) C-<down>: Fetch the next later old shell command.      
M-r: Begin an incremental regexp search of old shell commands.      
C-c C-x: Fetch the next subsequent command from the history.    
C-c . : Fetch one argument from an old shell command.       
C-c C-l: Display the buffer's history of shell commands in another window (comint-dynamic-list-input-ring).</down></up></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[All-pairs shortest path]]></title>
    <link href="http://creasyw.github.io/blog/2013/09/30/johnsons-algorithm/"/>
    <updated>2013-09-30T23:49:00-05:00</updated>
    <id>http://creasyw.github.io/blog/2013/09/30/johnsons-algorithm</id>
    <content type="html"><![CDATA[<p>The question comes from the online course <em>Algorithm Design and Analysis (Part II)</em> in coursera. It is an <a href="http://en.wikipedia.org/wiki/Shortest_path_problem#All-pairs_shortest_paths">all-pairs shortest path problem</a>. As mentioned in the wikipedia, a more straightforward solution with Floyd–Warshall algorithm takes \(O(N^3)\) complexity, and the more computational efficient approach is to use a combination of Dijkstra’s algorithm, Bellman-Ford algorithm, and Johnson’s algorithm, which chould decrease the complexity to \(O(N^2logN)\). I implement the latter one for more interesting and challenging. There are several obstacles make the implementation a little bit trickier than I thought.</p>

<p>I have tried two or three different versions of Dijkstra’s algorithm while solving other math puzzles, and this time I use the built-in heapq function in Python. Keeping the “about-to explore” nodes in order and extracting the smallest/largest cost one in every iteration are the essense of this algorithm. But the cost to every node has to be updated when a node moves from “about-to explore” to “fully explored” category. At first, I just remove the original value and push the updated one into the heap. Because the heapq has no updated or remove methods, I can only use the remove mehtod of the list. This works fine for small amount of nodes (200) but the heap cannot keep right struture when the data becomes just a little bigger (500). Then I have to <em>heapify</em> it every time I update a “about-to explore” node.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption class='code-header' style='margin-bottom:-5px;'><span>Dijkstra’s Algorithm</span><a href='https://github.com/creasyw/learning/blob/master/courses/algo_analysis_II/hw4/dijkstras.py'>link</a></figcaption> <div class="CodeRay">
  <div class="code"><pre>
<span class="keyword">def</span> <span class="function">dijkstras</span>(graph, start):
    <span class="comment"># keep a record of the distance of the nodes from the start vertex</span>
    distance = defaultdict()
    <span class="comment"># keep track of the candidates for the next move</span>
    index = defaultdict()
    <span class="comment"># store the cost and node into heap using cost as the key</span>
    heap = []
    heapq.heapify(heap)
    <span class="comment">#will be used to trace the path of the sjortest distance to each node</span>
    distance[start] = <span class="integer">0</span>
    <span class="keyword">if</span> start <span class="keyword">in</span> graph <span class="keyword">and</span> <span class="predefined">type</span>(graph[start])==<span class="predefined">dict</span>:
        <span class="keyword">for</span> (node, cost) <span class="keyword">in</span> graph[start].items():
            heap_update(heap, index, node, cost)
    <span class="keyword">else</span>:
        <span class="keyword">return</span> distance
    <span class="comment">#initially all nodes are yet to be explored</span>
    <span class="keyword">while</span> <span class="predefined">len</span>(index) &amp;gt; <span class="integer">0</span>:
        <span class="comment"># need to extract the node with the minimum path</span>
        node, cost = heap_pop(heap, index)
        <span class="comment"># store the node into known graph</span>
        distance[node] = cost
        <span class="comment"># update the knowledge according to existing node</span>
        <span class="keyword">if</span> node <span class="keyword">in</span> graph <span class="keyword">and</span> <span class="predefined">type</span>(graph[node])==<span class="predefined">dict</span>:
            <span class="keyword">for</span> (node, localcost) <span class="keyword">in</span> graph[node].items():
                <span class="keyword">if</span> node <span class="keyword">not</span> <span class="keyword">in</span> distance:
                    heap_update(heap, index, node, localcost+cost)
    <span class="keyword">return</span> distance
</pre></div>
</div>
 </figure></notextile></div></p>

<p>The Bellman-Ford algorithm is more expensive compared with Dijkstra’s algirhtm if the graph is densily connected, but it deals with negative edge cost. This is also the one that helps me fully appreciate the dynamic programming.The implementation is intuitive and straightforward. For every vertex, the brutal force search performs to find the current optimal solution based on the previous knowledge. The optimization for space complexity is to only store the most recent result–keep an 2*N array and use a pointer filp-flop in every iteration is more effecient than keeping two 1*N array, discarding the older one and reclaiming a new one in every iteration. Aother optimization I make is to store the “about-to explore” nodes in a bucket, just as what Dijkstra’s does, which eliminates plenty of unnecessary calculation. But its tricky aspect is that because this algorithm is computing “distributed”, different from the “centralized” spanning of Dijkstra’s, if several “exploring” vertices point to a same “about-to explore” vertex, only the optimal cost should be kept.</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption class='code-header' style='margin-bottom:-5px;'><span>Bellman-Ford Algorithm</span><a href='https://github.com/creasyw/learning/blob/master/courses/algo_analysis_II/hw4/bellman_ford.py'>link</a></figcaption> <div class="CodeRay">
  <div class="code"><pre>
<span class="keyword">def</span> <span class="function">bellman_ford</span> (arr, start, size):
    <span class="error">“</span><span class="error">”</span><span class="error">”</span> The <span class="predefined">input</span> arr stores <span class="predefined">all</span> info of the graph <span class="keyword">in</span> a dictionary.
        The basic element <span class="keyword">in</span> the arr are three-columns data <span class="error">–</span> 
        [start_point, end_point, cost]<span class="error">”</span><span class="error">”</span><span class="error">”</span>
    count = <span class="integer">1</span>
    data = np.zeros((<span class="integer">2</span>, size+<span class="integer">1</span>))
    <span class="comment"># initialization</span>
    data.fill(<span class="predefined">float</span>(<span class="error">“</span>inf<span class="error">”</span>))
    data[<span class="integer">0</span>, start] = <span class="integer">0</span>
    bucket = {}
    <span class="keyword">for</span> i <span class="keyword">in</span> arr[start]:
        bucket[i] = {start:arr[start][i]}&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;<span class="keyword">for</span> i <span class="keyword">in</span> <span class="predefined">range</span>(<span class="integer">1</span>, size):
    <span class="comment"># use set() to make sure start points in the next round are unique</span>
    candidate = <span class="predefined">set</span>()
    previous = count ^ <span class="integer">1</span>
    data[count] = data[previous]
    <span class="keyword">for</span> v <span class="keyword">in</span> bucket:
        data[count, v] = <span class="predefined">min</span>(data[previous, v], \
        data[previous, bucket[v].keys()[<span class="integer">0</span>]] \
        +bucket[v].values()[<span class="integer">0</span>])
        candidate.add(v)
    <span class="comment"># stop early if there is no place to span</span>
    <span class="keyword">if</span> (data[count]==data[previous]).all():
        <span class="keyword">break</span>
    <span class="comment"># update the bucket</span>
    bucket = {}
    <span class="keyword">for</span> j <span class="keyword">in</span> candidate:
        <span class="keyword">for</span> k <span class="keyword">in</span> arr[j]:
            <span class="keyword">if</span> (k <span class="keyword">in</span> bucket <span class="keyword">and</span> data[count,j]+arr[j][k] &amp;lt; \
              data[count, bucket[k].keys()[<span class="integer">0</span>]] + \
              bucket[k].values()[<span class="integer">0</span>]) <span class="keyword">or</span> k <span class="keyword">not</span> <span class="keyword">in</span> bucket:
                bucket[k] = {}
                bucket[k][j] = arr[j][k]
    <span class="keyword">if</span> <span class="keyword">not</span> bucket:
        <span class="keyword">break</span>
    count = previous

<span class="comment"># check cycle with negative sum</span>
previous = count ^ <span class="integer">1</span>
data[count] = data[previous]
<span class="keyword">for</span> v <span class="keyword">in</span> bucket:
    data[count, v] = <span class="predefined">min</span>(data[previous,v], \
        data[previous, bucket[v].keys()[<span class="integer">0</span>]]+bucket[v].values()[<span class="integer">0</span>])
<span class="keyword">if</span> (data[count]== data[previous]).all():
    <span class="keyword">return</span> data[count]
<span class="keyword">else</span>:
    <span class="keyword">return</span> <span class="predefined">float</span>(<span class="string"><span class="delimiter">&quot;</span><span class="content">inf</span><span class="delimiter">&quot;</span></span>) </pre></div>
</div>
 </figure></notextile></div>
</code></pre>

<p>Finally, the two algorithms above are connected by the Johnson’s algorithm. Dijkstra’s algorithm cannot deal with negative edge costs, but much more fast than Bellman-Ford especially in the case of “all-pairs”. Furthermore, the negative costs cannot be got rid of by adding uniformly for every edge. Johnson’s algorithm neatly solves it by adding pseudo-node to find weights of vertices and changing values of edges concerning their connected vertices. There is no hidden obstacle in the implementation. Only the special care should be taken for manipulating the nodes. It reminds me coding in C…</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption class='code-header' style='margin-bottom:-5px;'><span>Johnson’s Algorithm</span><a href='https://github.com/creasyw/learning/blob/master/courses/algo_analysis_II/hw4/johnsons.py'>link</a></figcaption> <div class="CodeRay">
  <div class="code"><pre>
<span class="keyword">def</span> <span class="function">johonsons</span>(data, vertex):
    d1 = data.copy()
    <span class="comment"># make psedu node pointing to all other nodes with zero cost</span>
    plus1 = vertex+<span class="integer">1</span>
    d1[plus1] = {}
    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="predefined">range</span>(<span class="integer">1</span>, plus1):
        d1[plus1][i] = <span class="integer">0</span>
    <span class="comment"># calculate the reweight vector</span>
    reweight = bellman_ford(d1, plus1, plus1)
    <span class="comment"># reweight all cost to make it nonnegative</span>
    <span class="keyword">if</span> <span class="predefined">type</span>(reweight) == <span class="predefined">float</span>:
        <span class="comment"># stop if there is any negative cycle in the graph</span>
        <span class="keyword">return</span> <span class="predefined-constant">None</span>
    <span class="keyword">else</span>:
        <span class="keyword">for</span> i <span class="keyword">in</span> data:
            <span class="keyword">for</span> k <span class="keyword">in</span> data[i]:
                data[i][k] = data[i][k]+reweight[i]-reweight[k]&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;<span class="keyword">return</span> [<span class="predefined">min</span>(reconvert(reweight,vertex,dijkstras(data,i),i))\
        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="predefined">range</span>(<span class="integer">1</span>,vertex+<span class="integer">1</span>)] </pre></div>
</div>
 </figure></notextile></div>
</code></pre>

<p>The overall algorithm solves the question and runs kind of standard. Still, I do not satisfy with the update procedure of heap. I will write a new version of this data structure in the near future and see if it can provide significant boost for the performance.</p>

<p>p.s. The vistualization of code block is optimized from the original Octopress style to Github-style based on the <a href="http://blog.codebykat.com/2013/05/23/gorgeous-octopress-codeblocks-with-coderay/">tutorial</a>.<br />
p.p.s. The inline latex-style formula comes with Kramdown, MathJax and <a href="http://yoyzhou.github.io/blog/2012/08/05/add-latex-support-for-octopress/">this tutorial</a>. Besides, there is <a href="http://brianbuccola.github.io/blog/2012-11-28-latex-math-in-octopress.html">another minor bug to deal with</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Reading note of SICP (4)]]></title>
    <link href="http://creasyw.github.io/blog/2013/08/10/reading-note-of-sicp-4/"/>
    <updated>2013-08-10T00:00:00-05:00</updated>
    <id>http://creasyw.github.io/blog/2013/08/10/reading-note-of-sicp-4</id>
    <content type="html"><![CDATA[<div class="post">
  Aug. 10th. Complete the 1st chapter of sicp.<br /><br />
  
  I really appreciate the exercises within each subsections, because I can feel that they are well designed. I used to have the same feeling when I did the homework from Dan's course of programming languages. The exercises make the general concepts concrete and doable.
  <br /><br />
  The abstraction is far from merely making the code more structured and readable. It is a design choice. Sometimes, it takes experience to find out where should be abstracted. And sometimes, it takes much more endeavors than simply mix everything together. But once the choice of abstraction is right, the program becomes clearer, and it increases many degrees of freedom for the design afterwards.</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Reading note of SICP (3)]]></title>
    <link href="http://creasyw.github.io/blog/2013/08/08/reading-note-of-sicp-3/"/>
    <updated>2013-08-08T00:00:00-05:00</updated>
    <id>http://creasyw.github.io/blog/2013/08/08/reading-note-of-sicp-3</id>
    <content type="html"><![CDATA[<div class="post">
&nbsp;<br />At the end of the 1st chapter, it enumerates the basic reason for the powerful lisp: first-order procedure.<br /><br />The major "privileges" of the first-order elements are:<br />1) They may be named by variables.<br />2) They may be passed as arguments to procedures.<br />3) They may be returned as the results of procedures.<br />4) They may be included in data structures.<br />They can be crucial abstraction mechanism permitting to express the general methods of computing as explicit elements in programming language, so that they can be handled just like other computational elements. The expression power is enormous.<br /><br />I have already been used to use the first two kinds of procedures, but the last two actually make the program even more expressive and powerful. Those are also the attractive properties sharing among functional programming languages.</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Reading note of SICP (2)]]></title>
    <link href="http://creasyw.github.io/blog/2013/08/07/reading-note-of-sicp-2/"/>
    <updated>2013-08-07T00:00:00-05:00</updated>
    <id>http://creasyw.github.io/blog/2013/08/07/reading-note-of-sicp-2</id>
    <content type="html"><![CDATA[<div class="post">
<br />While I am reading, I always try to distinguish which part of thoughts I used to learn from here when I read it for the first time, and which part I learned from Dan's course. And, surprisingly enough, I learned almost all basic factors from Dan, though I always felt I learned a lot of things last year when I began to read it.<br /><br />The name of this book is perfect for the content -- Structure and Interpretation of Computer Programs. It does not teach about how to program, nor a specific programming language. Of course it is a legacy book. But it seems to me that I cannot get enough from this book unless I have mastered quite a few programming languages. After Dan taught me everything about basic aspects of programming languages and I played with Ruby and Racket for a long time, even after I leaned all those "nontrivial" trivial things about C++, when I read it now, I am able to distinguish which part is the essence and which part is written just for the ease of learning, and I can fully focus on how to put different abstractions into different layers-- in other words, learning the structure and interpretation of computer programs.<br /><br />I read a comment, saying that Chapter 4 and 5 are the essence of the book. Hopefully, I can finish reading it before September, and leave enough time for Design Patterns.</div>
]]></content>
  </entry>
  
</feed>
